import pandas as pd
import numpy as np
import sklearn as sk
from pandas.plotting import scatter_matrix
from sklearn import model_selection
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn import linear_model #it is good at predicting training model but not good with non linear data
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_boston

boston= load_boston()
#print(boston)
#clean the data--
#target= dependent variable upon which we have to act, y values
#data= x values that are independent variables
#feature names= is the column names

df_x=pd.DataFrame(boston.data,columns=boston.feature_names)
df_y=pd.DataFrame(boston.target)
print(df_x.describe())


#initialise linear regression model
reg=linear_model.LinearRegression()

#Split the data into 30 training and 70 testing data
x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.30,random_state=42)

#train the model for training data
reg.fit(x_train,y_train)

#print the coeffcients of each featureof ourmodel
print(reg.coef_)

#print y predictions
y_pred=reg.predict(x_test)
print(y_pred)

#print actual vales with predictions on y
print(y_test,y_pred)


#Check accuracy of our model for mean squared error:
print(np.mean(y_pred - y_test)**2)

#using mean squared error with sklearn---loss function
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_pred,y_test))


#we are getting closer to 21 which is god since we are close to the actual values.
